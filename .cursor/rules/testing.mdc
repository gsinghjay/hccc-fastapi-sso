---
description: Test suite implementation guidelines
globs: tests/**/test_*.py, tests/core/test_*.py, tests/e2e/test_*.py
---

# Testing Standards

## Test Organization
- Group related tests in classes using descriptive names
- Use clear, descriptive test function names that indicate the scenario being tested
- Follow FastAPI's naming convention: `test_read_*` for GET, `test_create_*` for POST, etc.
- Keep test files organized parallel to the application structure

## Test Client Usage
```python
@pytest.fixture
def client() -> Generator[TestClient, None, None]:
    """Test client fixture with dependency overrides"""
    app.dependency_overrides[get_settings] = get_settings_override
    with TestClient(app) as test_client:
        yield test_client
    app.dependency_overrides.clear()
```

## Dependency Overrides
- Override settings and dependencies for testing environment
- Use fixture-based dependency injection
- Clear overrides after tests complete
- Provide test-specific configuration values

## Test Structure
```python
class TestEndpoint:
    """Group related endpoint tests together"""
    
    def test_read_endpoint(self, client: TestClient) -> None:
        """Test successful endpoint read"""
        response = client.get("/path")
        assert response.status_code == 200
        assert response.json() == expected_data

    def test_endpoint_validation(self, client: TestClient) -> None:
        """Test response validates against schema"""
        response = client.get("/path")
        data = response.json()
        ModelName(**data)  # Validate against Pydantic model
```

## Parameterized Testing
```python
@pytest.mark.parametrize(
    "input_value,expected_result",
    [
        ("valid_input", "expected_output"),
        ("another_input", "another_output"),
    ],
)
def test_parameterized(
    self, 
    input_value: str, 
    expected_result: str,
    client: TestClient
) -> None:
    """Test multiple scenarios using parameters"""
    response = client.post("/path", json={"value": input_value})
    assert response.json()["result"] == expected_result
```

## Response Validation
- Always validate responses against Pydantic models
- Test both successful and error scenarios
- Verify correct status codes
- Check response structure and content

## Test Coverage Requirements
- 100% route coverage
- 90% service layer coverage
- Test all error conditions
- Verify OpenAPI schema compliance

## Configuration Testing
- Test environment variable loading
- Verify configuration validation
- Test computed properties
- Mock sensitive data appropriately
- Test DEBUG flag behavior

## Best Practices
1. Use `TestClient` from FastAPI for HTTP testing
2. Group related tests in classes
3. Use clear, descriptive test names
4. Validate responses against Pydantic models
5. Use parameterized tests for multiple scenarios
6. Override dependencies appropriately
7. Clean up resources after tests
8. Follow FastAPI's naming conventions
9. Keep tests focused and isolated
10. Use proper type annotations

## Example Test Structure
```python
from fastapi.testclient import TestClient
from app.schemas import ResponseModel

class TestUserEndpoints:
    def test_read_users(self, client: TestClient) -> None:
        response = client.get("/users")
        assert response.status_code == 200
        ResponseModel(**response.json())

    def test_create_user(self, client: TestClient) -> None:
        response = client.post("/users", json=user_data)
        assert response.status_code == 201
        ResponseModel(**response.json())

    @pytest.mark.parametrize("user_id,expected_status", [
        (1, 200),
        (999, 404),
    ])
    def test_read_user(
        self,
        user_id: int,
        expected_status: int,
        client: TestClient
    ) -> None:
        response = client.get(f"/users/{user_id}")
```

## E2E Test Organization
- Keep e2e tests in `tests/e2e/` directory
- Use Page Object Model pattern in `tests/e2e/pages/`
- Mirror API structure in e2e test files
- Use shared fixtures from parent conftest.py where appropriate

## E2E Test Configuration
- Use FastAPI CLI for development server
- Configure browser settings in e2e/conftest.py
- Share test settings with unit tests via parent conftest.py
- Use session-scoped fixtures for long-lived resources

## Page Object Model Standards
- Extend BasePage for all page objects
- Implement network request handling in base page
- Document all page object methods
- Keep UI interaction logic separate from test assertions

## E2E Test Naming Conventions
- Test files: `test_<feature>.py`
- Page objects: `<Feature>Page` class names
- Test functions: `test_<scenario>_<expected_result>`
- Mark all e2e tests with @pytest.mark.e2e

## E2E Test Best Practices
- Run tests against FastAPI dev server
- Clean up resources after each test
- Use explicit waits for network requests
- Handle both success and error scenarios
- Document test scenarios in docstrings